"team_name": "Zephyr" # Your team name
"eval_method": ["mcqa", "quantiz"] # mcqa, reward, rag, quantiz
"task_type": "causal_lm" # causal_lm, seq2seq
"policy_model_path": "JCHAVEROT/Qwen2-0.5B-Chat_SFT_LoRA" # Your path to the final checkpoint
"reference_model_path": "Qwen/Qwen2-0.5B-Instruct" # The repo id of your pretrained reference model
"quantized_policy_model_path": "SylvainShan/Qwen2SFT_GPTQ_8bits" # Your path to the final quantized checkpoint
"rag_policy_model_path": "./checkpoints/best_model_rag/" # Your path to the final RAG checkpoint
"test_data_path": "./datasets/mcqa_quick_test.jsonl" # Your path to the test data
"dpo_model_args": # Put any model arguments required to load your DPO model below
  "device": "cuda" # Device to run the model on
  "beta": "0.1" # beta value for DPO
"rag_model_args": # Put any model arguments required to load your rag model below
  "encoder_model_path": "facebook/bart-large"
  "retriever_model_path": "./checkpoints/rag_retriever"
  "document_dir": "./data/documents"
"quantized_model_args": # Any required arguments to load your quantized model below
  "device": "cuda" # Device to run the model on
  "beta": "0.1" # beta value for DPO